# MLSharp æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº† MLSharp å¯ä»¥å®æ–½çš„å„ç§æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆï¼Œä»¥è¿›ä¸€æ­¥æå‡æ¨ç†é€Ÿåº¦å’Œå‡å°‘å†…å­˜å ç”¨ã€‚

## å·²å®ç°çš„ä¼˜åŒ–

### 1. æ··åˆç²¾åº¦æ¨ç† (AMP)
- **æ˜¾å­˜å‡å°‘**: 40-50%
- **é€Ÿåº¦æå‡**: 20-30%
- **çŠ¶æ€**: âœ… å·²å®ç°

### 2. TensorFloat32 (TF32)
- **é€‚ç”¨**: NVIDIA Ampere æ¶æ„ (RTX 30/40 ç³»åˆ—)
- **é€Ÿåº¦æå‡**: 1.5-2å€
- **çŠ¶æ€**: âœ… å·²å®ç°

### 3. cuDNN Benchmark
- **é€Ÿåº¦æå‡**: 10-20%
- **çŠ¶æ€**: âœ… å·²å®ç°

### 4. è¾“å…¥å°ºå¯¸æ§åˆ¶
- **æ˜¾å­˜å‡å°‘**: 30-70%
- **çŠ¶æ€**: âœ… å·²å®ç°

### 5. CPU å¤šçº¿ç¨‹ä¼˜åŒ–
- **é€‚ç”¨**: CPU æ¨¡å¼
- **çŠ¶æ€**: âœ… å·²å®ç°

### 6. éé˜»å¡æ•°æ®ä¼ è¾“
- **çŠ¶æ€**: âœ… å·²å®ç°

### 7. å†…å­˜ç›‘æ§
- **çŠ¶æ€**: âœ… å·²å®ç° (Prometheus é›†æˆ)

---

## å¾…å®æ–½çš„ä¼˜åŒ–æ–¹æ¡ˆ

### ğŸš€ æ–¹æ¡ˆ 1: æ¨¡å‹é‡åŒ– (Model Quantization)

**æè¿°**: å°†æ¨¡å‹æƒé‡ä» FP32 è½¬æ¢ä¸º INT8ï¼Œå¤§å¹…å‡å°‘æ˜¾å­˜å ç”¨ã€‚

**ä¼˜åŠ¿**:
- æ˜¾å­˜å ç”¨å‡å°‘ 75%ï¼ˆFP32 â†’ INT8ï¼‰
- æ¨ç†é€Ÿåº¦æå‡ 2-4 å€
- æ”¯æŒ CPU å’Œ GPU åŠ é€Ÿ

**å®ç°æ–¹æ¡ˆ**:
```python
import torch.quantization as quantization

# åŠ¨æ€é‡åŒ–
quantized_model = torch.quantization.quantize_dynamic(
    model,
    {torch.nn.Linear, torch.nn.Conv2d},
    dtype=torch.qint8
)

# é™æ€é‡åŒ–ï¼ˆéœ€è¦æ ¡å‡†ï¼‰
model.qconfig = torch.quantization.get_default_qconfig('fbgemm')
quantized_model = torch.quantization.prepare(model)
quantized_model = torch.quantization.convert(quantized_model)
```

**é¢„æœŸæ•ˆæœ**:
- æ˜¾å­˜: 5GB â†’ 1.25GB
- é€Ÿåº¦: æå‡ 2-3 å€
- ç²¾åº¦æŸå¤±: < 1%

**å®æ–½éš¾åº¦**: â­â­â­

---

### âš¡ æ–¹æ¡ˆ 2: æ¨¡å‹å‰ªæ (Model Pruning)

**æè¿°**: ç§»é™¤æ¨¡å‹ä¸­ä¸é‡è¦çš„æƒé‡ï¼Œå‡å°‘æ¨¡å‹å¤§å°ã€‚

**ä¼˜åŠ¿**:
- æ¨¡å‹å¤§å°å‡å°‘ 30-50%
- æ¨ç†é€Ÿåº¦æå‡
- ç²¾åº¦æŸå¤±å¯æ§

**å®ç°æ–¹æ¡ˆ**:
```python
import torch.nn.utils.prune as prune

# éç»“æ„åŒ–å‰ªæ
for name, module in model.named_modules():
    if isinstance(module, torch.nn.Conv2d):
        prune.l1_unstructured(module, name='weight', amount=0.2)

# ç»“æ„åŒ–å‰ªæï¼ˆæ›´é«˜æ•ˆï¼‰
prune.ln_structured(module, name='weight', amount=0.3, n=2, dim=0)
```

**é¢„æœŸæ•ˆæœ**:
- æ¨¡å‹å¤§å°: å‡å°‘ 30-50%
- é€Ÿåº¦: æå‡ 1.5-2 å€
- ç²¾åº¦æŸå¤±: 1-2%

**å®æ–½éš¾åº¦**: â­â­â­â­â­

---

### ğŸ“¦ æ–¹æ¡ˆ 3: æ‰¹å¤„ç†ä¼˜åŒ– (Batch Processing)

**æè¿°**: æ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªå›¾åƒï¼Œæé«˜ GPU åˆ©ç”¨ç‡ã€‚

**ä¼˜åŠ¿**:
- GPU åˆ©ç”¨ç‡æå‡ 50-80%
- å•å›¾åƒå¤„ç†æˆæœ¬é™ä½
- é€‚åˆæ‰¹é‡ä»»åŠ¡

**å®ç°æ–¹æ¡ˆ**:
```python
def predict_batch(self, images: List[np.ndarray], f_px_list: List[float]):
    batch_size = len(images)
    
    # å‡†å¤‡æ‰¹é‡è¾“å…¥
    images_pt = torch.stack([
        torch.from_numpy(img).permute(2, 0, 1) / 255.0
        for img in images
    ]).to(self.device)
    
    disparity_factors = torch.tensor([f / w for f, w in zip(f_px_list, 
        [img.shape[1] for img in images])], dtype=torch.float32, device=self.device)
    
    # æ‰¹é‡æ¨ç†
    gaussians_batch = self.predictor(images_pt, disparity_factors)
    
    return gaussians_batch
```

**API ç«¯ç‚¹**:
```python
@app.post("/api/predict/batch")
async def predict_batch(files: List[UploadFile] = File(...)):
    results = []
    for file in files:
        result = await self._handle_predict(file)
        results.append(result)
    return results
```

**é¢„æœŸæ•ˆæœ**:
- æ‰¹é‡å¤§å° 4: é€Ÿåº¦æå‡ 50-80%
- æ‰¹é‡å¤§å° 8: é€Ÿåº¦æå‡ 80-120%

**å®æ–½éš¾åº¦**: â­

---

### ğŸ”„ æ–¹æ¡ˆ 4: æ¨ç†ç¼“å­˜ (Inference Caching)

**æè¿°**: ç¼“å­˜ç›¸ä¼¼å›¾åƒçš„æ¨ç†ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—ã€‚

**ä¼˜åŠ¿**:
- ç›¸ä¼¼å›¾åƒå¤„ç†é€Ÿåº¦æå‡ 90%+
- å‡å°‘é‡å¤è®¡ç®—
- é€‚åˆç›¸ä¼¼åœºæ™¯å¤„ç†

**å®ç°æ–¹æ¡ˆ**:
```python
from functools import lru_cache
import hashlib

class ModelManager:
    def __init__(self):
        self.cache = {}
        self.cache_hits = 0
        self.cache_misses = 0
    
    def _get_image_hash(self, image: np.ndarray) -> str:
        """è®¡ç®—å›¾åƒå“ˆå¸Œ"""
        return hashlib.md5(image.tobytes()).hexdigest()
    
    def predict_with_cache(self, image: np.ndarray, f_px: float):
        """å¸¦ç¼“å­˜çš„é¢„æµ‹"""
        image_hash = self._get_image_hash(image)
        
        # æ£€æŸ¥ç¼“å­˜
        if image_hash in self.cache:
            self.cache_hits += 1
            Logger.info(f"ç¼“å­˜å‘½ä¸­: {self.cache_hits}/{self.cache_hits + self.cache_misses}")
            return self.cache[image_hash]
        
        # æ‰§è¡Œæ¨ç†
        self.cache_misses += 1
        result = self.predict(image, f_px)
        
        # ç¼“å­˜ç»“æœ
        self.cache[image_hash] = result
        
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.cache) > 100:
            self.cache.pop(next(iter(self.cache)))
        
        return result
```

**é¢„æœŸæ•ˆæœ**:
- ç¼“å­˜å‘½ä¸­ç‡ 30%: é€Ÿåº¦æå‡ 30%
- ç¼“å­˜å‘½ä¸­ç‡ 50%: é€Ÿåº¦æå‡ 50%
- ç¼“å­˜å‘½ä¸­ç‡ 80%: é€Ÿåº¦æå‡ 80%

**å®æ–½éš¾åº¦**: â­

---

### ğŸ§  æ–¹æ¡ˆ 5: çŸ¥è¯†è’¸é¦ (Knowledge Distillation)

**æè¿°**: ä½¿ç”¨æ›´å¤§çš„æ•™å¸ˆæ¨¡å‹è®­ç»ƒæ›´å°çš„å­¦ç”Ÿæ¨¡å‹ã€‚

**ä¼˜åŠ¿**:
- æ¨¡å‹å¤§å°å‡å°‘ 50-70%
- ä¿æŒé«˜ç²¾åº¦
- æ¨ç†é€Ÿåº¦æå‡ 2-3 å€

**å®ç°æ–¹æ¡ˆ**:
```python
def distillation_loss(student_output, teacher_output, labels, T=2.0, alpha=0.5):
    """çŸ¥è¯†è’¸é¦æŸå¤±å‡½æ•°"""
    # è½¯æŸå¤±ï¼ˆçŸ¥è¯†è’¸é¦ï¼‰
    soft_loss = nn.KLDivLoss()(
        F.log_softmax(student_output/T, dim=1),
        F.softmax(teacher_output/T, dim=1)
    ) * (T*T * alpha)
    
    # ç¡¬æŸå¤±ï¼ˆçœŸå®æ ‡ç­¾ï¼‰
    hard_loss = F.cross_entropy(student_output, labels) * (1 - alpha)
    
    return soft_loss + hard_loss

# è®­ç»ƒæµç¨‹
for batch in dataloader:
    inputs, labels = batch
    
    # æ•™å¸ˆæ¨¡å‹æ¨ç†ï¼ˆä¸è®¡ç®—æ¢¯åº¦ï¼‰
    with torch.no_grad():
        teacher_output = teacher_model(inputs)
    
    # å­¦ç”Ÿæ¨¡å‹æ¨ç†
    student_output = student_model(inputs)
    
    # è®¡ç®—è’¸é¦æŸå¤±
    loss = distillation_loss(student_output, teacher_output, labels)
    
    # åå‘ä¼ æ’­
    loss.backward()
    optimizer.step()
```

**é¢„æœŸæ•ˆæœ**:
- æ¨¡å‹å¤§å°: å‡å°‘ 50-70%
- é€Ÿåº¦: æå‡ 2-3 å€
- ç²¾åº¦æŸå¤±: < 2%

**å®æ–½éš¾åº¦**: â­â­â­â­â­

---

### ğŸ¯ æ–¹æ¡ˆ 6: æ¢¯åº¦æ£€æŸ¥ç‚¹ (Gradient Checkpointing)

**æè¿°**: ä»¥è®¡ç®—æ¢å†…å­˜ï¼Œå‡å°‘ä¸­é—´æ¿€æ´»å€¼çš„å­˜å‚¨ã€‚

**ä¼˜åŠ¿**:
- æ˜¾å­˜å ç”¨å‡å°‘ 30-50%
- é€‚åˆè¶…å¤§æ¨¡å‹
- æ¨ç†é€Ÿåº¦ç•¥å¾®é™ä½ï¼ˆå¯æ¥å—ï¼‰

**å®ç°æ–¹æ¡ˆ**:
```python
from torch.utils.checkpoint import checkpoint

class CheckpointedModel(nn.Module):
    def __init__(self, original_model):
        super().__init__()
        self.original_model = original_model
    
    def forward(self, x):
        # ä½¿ç”¨æ£€æŸ¥ç‚¹é‡æ–°è®¡ç®—ä¸­é—´æ¿€æ´»å€¼
        x = checkpoint(self.original_model.block1, x)
        x = checkpoint(self.original_model.block2, x)
        x = checkpoint(self.original_model.block3, x)
        return x

# åº”ç”¨åˆ°é¢„æµ‹å™¨
self.checkpointed_predictor = CheckpointedModel(self.predictor)
```

**é…ç½®é€‰é¡¹**:
```yaml
# config.yaml
optimization:
  gradient_checkpointing: false  # é»˜è®¤å…³é—­
  checkpoint_segments: 3         # æ£€æŸ¥ç‚¹åˆ†æ®µæ•°
```

**å‘½ä»¤è¡Œå‚æ•°**:
```bash
# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
python app.py --gradient-checkpointing

# è®¾ç½®æ£€æŸ¥ç‚¹åˆ†æ®µæ•°
python app.py --gradient-checkpointing --checkpoint-segments 4
```

**é¢„æœŸæ•ˆæœ**:
- æ˜¾å­˜: å‡å°‘ 30-50%
- é€Ÿåº¦: é™ä½ 10-20%
- é€‚ç”¨: æ˜¾å­˜ä¸è¶³æ—¶

**å®æ–½éš¾åº¦**: â­â­

---

### ğŸ—œï¸ æ–¹æ¡ˆ 7: åŠ¨æ€è¾“å…¥å°ºå¯¸ (Dynamic Input Size)

**æè¿°**: æ ¹æ®å›¾åƒå†…å®¹è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è¾“å…¥å°ºå¯¸ã€‚

**ä¼˜åŠ¿**:
- ç®€å•å›¾åƒä½¿ç”¨è¾ƒå°å°ºå¯¸ï¼ŒèŠ‚çœæ˜¾å­˜
- å¤æ‚å›¾åƒä½¿ç”¨è¾ƒå¤§å°ºå¯¸ï¼Œä¿è¯è´¨é‡
- æ™ºèƒ½å¹³è¡¡è´¨é‡å’Œæ€§èƒ½

**å®ç°æ–¹æ¡ˆ**:
```python
import cv2
import numpy as np

def analyze_image_complexity(self, image: np.ndarray) -> Tuple[int, int]:
    """
    åˆ†æå›¾åƒå¤æ‚åº¦å¹¶è¿”å›æ¨èçš„è¾“å…¥å°ºå¯¸
    
    Args:
        image: è¾“å…¥å›¾åƒ (H, W, 3)
    
    Returns:
        æ¨èçš„è¾“å…¥å°ºå¯¸ (width, height)
    """
    # è½¬æ¢ä¸ºç°åº¦å›¾
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image
    
    # è®¡ç®—è¾¹ç¼˜æ£€æµ‹
    edges = cv2.Canny(gray, 100, 200)
    edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
    
    # è®¡ç®—å›¾åƒç†µï¼ˆä¿¡æ¯é‡ï¼‰
    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
    hist = hist / np.sum(hist)
    entropy = -np.sum(hist * np.log2(hist + 1e-10))
    
    # è®¡ç®—é¢œè‰²å¤æ‚åº¦
    if len(image.shape) == 3:
        colors = np.unique(image.reshape(-1, 3), axis=0)
        color_complexity = len(colors) / (256 * 256 * 256)
    else:
        color_complexity = 0
    
    # ç»¼åˆè¯„åˆ† (0-1)
    complexity_score = (
        edge_density * 0.4 +      # è¾¹ç¼˜å¯†åº¦æƒé‡ 40%
        entropy / 8.0 * 0.4 +     # ç†µæƒé‡ 40%
        color_complexity * 0.2     # é¢œè‰²å¤æ‚åº¦æƒé‡ 20%
    )
    
    Logger.info(f"å›¾åƒå¤æ‚åº¦åˆ†æ: è¾¹ç¼˜å¯†åº¦={edge_density:.3f}, ç†µ={entropy:.3f}, é¢œè‰²å¤æ‚åº¦={color_complexity:.3f}")
    Logger.info(f"ç»¼åˆå¤æ‚åº¦è¯„åˆ†: {complexity_score:.3f}")
    
    # æ ¹æ®å¤æ‚åº¦é€‰æ‹©å°ºå¯¸
    if complexity_score < 0.15:
        recommended_size = (512, 512)
        Logger.info(f"æ¨èè¾“å…¥å°ºå¯¸: 512x512 (ç®€å•å›¾åƒ)")
    elif complexity_score < 0.30:
        recommended_size = (768, 768)
        Logger.info(f"æ¨èè¾“å…¥å°ºå¯¸: 768x768 (ä¸­ç­‰å¤æ‚åº¦)")
    elif complexity_score < 0.50:
        recommended_size = (1024, 1024)
        Logger.info(f"æ¨èè¾“å…¥å°ºå¯¸: 1024x1024 (å¤æ‚å›¾åƒ)")
    else:
        recommended_size = (1536, 1536)
        Logger.info(f"æ¨èè¾“å…¥å°ºå¯¸: 1536x1536 (é«˜åº¦å¤æ‚)")
    
    return recommended_size
```

**é…ç½®é€‰é¡¹**:
```yaml
# config.yaml
inference:
  input_size: [1536, 1536]  # é»˜è®¤/æœ€å¤§å°ºå¯¸
  dynamic_input_size: false  # åŠ¨æ€è¾“å…¥å°ºå¯¸ï¼ˆé»˜è®¤å…³é—­ï¼‰
  min_input_size: 512        # æœ€å°è¾“å…¥å°ºå¯¸
  max_input_size: 1536       # æœ€å¤§è¾“å…¥å°ºå¯¸
```

**å‘½ä»¤è¡Œå‚æ•°**:
```bash
# å¯ç”¨åŠ¨æ€è¾“å…¥å°ºå¯¸
python app.py --dynamic-input-size

# è®¾ç½®æœ€å°/æœ€å¤§å°ºå¯¸
python app.py --dynamic-input-size --min-input-size 512 --max-input-size 1536
```

**é¢„æœŸæ•ˆæœ**:
- ç®€å•å›¾åƒ: æ˜¾å­˜å‡å°‘ 60-70%
- ä¸­ç­‰å›¾åƒ: æ˜¾å­˜å‡å°‘ 30-40%
- å¤æ‚å›¾åƒ: æ— æŸå¤±
- å¹³å‡: æ˜¾å­˜å‡å°‘ 30-50%

**å®æ–½éš¾åº¦**: â­â­

---

### ğŸ“Š æ–¹æ¡ˆ 8: æ¸è¿›å¼æ¨ç† (Progressive Inference)

**æè¿°**: å…ˆä½¿ç”¨ä½åˆ†è¾¨ç‡å¿«é€Ÿæ¨ç†ï¼Œå†æ ¹æ®éœ€è¦é€æ­¥æé«˜åˆ†è¾¨ç‡ã€‚

**ä¼˜åŠ¿**:
- å¿«é€Ÿé¢„è§ˆï¼ˆä½åˆ†è¾¨ç‡ï¼‰
- æŒ‰éœ€æå‡è´¨é‡
- èŠ‚çœä¸å¿…è¦çš„è®¡ç®—

**å®ç°æ–¹æ¡ˆ**:
```python
def progressive_predict(self, image: np.ndarray, max_size: int = 1536):
    """
    æ¸è¿›å¼æ¨ç†
    
    Args:
        image: è¾“å…¥å›¾åƒ
        max_size: æœ€å¤§è¾“å…¥å°ºå¯¸
    
    Returns:
        é«˜æ–¯ç»“æœ
    """
    sizes = [512, 768, 1024, max_size]
    
    # ç¬¬ä¸€é˜¶æ®µï¼šä½åˆ†è¾¨ç‡å¿«é€Ÿæ¨ç†
    gaussians = self.predict(image, input_size=(sizes[0], sizes[0]))
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´é«˜åˆ†è¾¨ç‡
    if self.needs_high_quality(gaussians):
        # ç¬¬äºŒé˜¶æ®µï¼šä¸­ç­‰åˆ†è¾¨ç‡
        gaussians = self.predict(image, input_size=(sizes[1], sizes[1]))
        
        if self.needs_high_quality(gaussians):
            # ç¬¬ä¸‰é˜¶æ®µï¼šé«˜åˆ†è¾¨ç‡
            gaussians = self.predict(image, input_size=(max_size, max_size))
    
    return gaussians

def needs_high_quality(self, gaussians):
    """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´é«˜è´¨é‡"""
    # å¯ä»¥åŸºäºé«˜æ–¯æ•°é‡ã€åˆ†å¸ƒç­‰æŒ‡æ ‡åˆ¤æ–­
    return len(gaussians) < 10000  # ç¤ºä¾‹é˜ˆå€¼
```

**é¢„æœŸæ•ˆæœ**:
- å¿«é€Ÿé¢„è§ˆ: é€Ÿåº¦æå‡ 4-6 å€
- æŒ‰éœ€æå‡: å¹³å‡èŠ‚çœ 50% è®¡ç®—
- ç”¨æˆ·ä½“éªŒ: æ›´å¥½çš„äº¤äº’ä½“éªŒ

**å®æ–½éš¾åº¦**: â­â­â­

---

### ğŸ”§ æ–¹æ¡ˆ 9: ONNX å¯¼å‡ºå’Œä¼˜åŒ–

**æè¿°**: å¯¼å‡º ONNX æ ¼å¼å¹¶è¿›è¡Œä¼˜åŒ–ã€‚

**ä¼˜åŠ¿**:
- è·¨å¹³å°å…¼å®¹æ€§
- æ¨ç†é€Ÿåº¦æå‡ 20-30%
- æ”¯æŒ TensorRT åŠ é€Ÿ

**å®ç°æ–¹æ¡ˆ**:
```python
import torch.onnx

def export_to_onnx(self, output_path: str = "model.onnx"):
    """å¯¼å‡ºæ¨¡å‹åˆ° ONNX æ ¼å¼"""
    self.predictor.eval()
    
    # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
    dummy_input = torch.randn(1, 3, 1536, 1536, device=self.device)
    dummy_disparity = torch.tensor([1.0], device=self.device)
    
    # å¯¼å‡º ONNX
    torch.onnx.export(
        self.predictor,
        (dummy_input, dummy_disparity),
        output_path,
        opset_version=14,
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        },
        input_names=['input', 'disparity'],
        output_names=['gaussians']
    )
    
    Logger.success(f"æ¨¡å‹å·²å¯¼å‡ºåˆ° {output_path}")

# ä½¿ç”¨ ONNX Runtime æ¨ç†
import onnxruntime as ort

class ONNXPredictor:
    def __init__(self, onnx_path: str):
        self.session = ort.InferenceSession(onnx_path)
    
    def predict(self, image: np.ndarray, f_px: float):
        """ä½¿ç”¨ ONNX Runtime æ¨ç†"""
        # é¢„å¤„ç†
        image_pt = torch.from_numpy(image).permute(2, 0, 1) / 255.0
        image_pt = image_pt.unsqueeze(0).numpy()
        
        # æ¨ç†
        outputs = self.session.run(
            None,
            {
                'input': image_pt,
                'disparity': np.array([f_px], dtype=np.float32)
            }
        )
        
        return outputs[0]
```

**é¢„æœŸæ•ˆæœ**:
- é€Ÿåº¦: æå‡ 20-30%
- å…¼å®¹æ€§: æ”¯æŒæ›´å¤šå¹³å°
- éƒ¨ç½²: æ›´å®¹æ˜“éƒ¨ç½²

**å®æ–½éš¾åº¦**: â­â­

---

### ğŸš„ æ–¹æ¡ˆ 10: TensorRT åŠ é€Ÿ

**æè¿°**: ä½¿ç”¨ NVIDIA TensorRT è¿›è¡Œæ¨ç†åŠ é€Ÿã€‚

**ä¼˜åŠ¿**:
- æ¨ç†é€Ÿåº¦æå‡ 3-5 å€
- æ˜¾å­˜å ç”¨å‡å°‘
- è‡ªåŠ¨ä¼˜åŒ–è®¡ç®—å›¾

**å®ç°æ–¹æ¡ˆ**:
```python
import tensorrt as trt
from torch2trt import torch2trt

def convert_to_tensorrt(self, max_batch_size: int = 1):
    """è½¬æ¢ä¸º TensorRT æ¨¡å‹"""
    self.predictor.eval()
    
    # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
    dummy_input = torch.randn(1, 3, 1536, 1536).cuda()
    dummy_disparity = torch.tensor([1.0]).cuda()
    
    # è½¬æ¢ä¸º TensorRT
    self.predictor_trt = torch2trt(
        self.predictor,
        [dummy_input, dummy_disparity],
        fp16_mode=True,
        max_workspace_size=1 << 30,  # 1GB
        max_batch_size=max_batch_size
    )
    
    Logger.success("æ¨¡å‹å·²è½¬æ¢ä¸º TensorRT æ ¼å¼")

def predict_with_tensorrt(self, image: np.ndarray, f_px: float):
    """ä½¿ç”¨ TensorRT æ¨ç†"""
    # é¢„å¤„ç†
    image_pt = torch.from_numpy(image).cuda().half().permute(2, 0, 1) / 255.0
    image_pt = image_pt.unsqueeze(0)
    disparity = torch.tensor([f_px]).cuda().half()
    
    # æ¨ç†
    with torch.no_grad():
        gaussians = self.predictor_trt(image_pt, disparity)
    
    return gaussians
```

**é¢„æœŸæ•ˆæœ**:
- é€Ÿåº¦: æå‡ 3-5 å€
- æ˜¾å­˜: å‡å°‘ 30%
- é€‚ç”¨: NVIDIA GPU

**å®æ–½éš¾åº¦**: â­â­â­â­

---

## ä¼˜åŒ–æ–¹æ¡ˆä¼˜å…ˆçº§

### ğŸ”¥ é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³å¯å®æ–½ï¼‰

1. **æ‰¹å¤„ç†ä¼˜åŒ–** - æœ€å®¹æ˜“å®ç°ï¼Œæ•ˆæœæ˜¾è‘—
2. **æ¨ç†ç¼“å­˜** - å®ç°ç®€å•ï¼Œé€‚åˆé‡å¤åœºæ™¯
3. **æ¢¯åº¦æ£€æŸ¥ç‚¹** - æ˜¾å­˜ä¸è¶³æ—¶çš„æ•‘å‘½ç¨»è‰
4. **åŠ¨æ€è¾“å…¥å°ºå¯¸** - æ™ºèƒ½åŒ–ï¼Œæå‡ç”¨æˆ·ä½“éªŒ

### â­ ä¸­ä¼˜å…ˆçº§ï¼ˆéœ€è¦ä¸€å®šå¼€å‘ï¼‰

5. **æ¨¡å‹é‡åŒ–** - æ•ˆæœæ˜¾è‘—ï¼Œéœ€è¦æµ‹è¯•ç²¾åº¦
6. **ONNX å¯¼å‡º** - æå‡å…¼å®¹æ€§ï¼Œæ”¯æŒæ›´å¤šå¹³å°
7. **TensorRT åŠ é€Ÿ** - NVIDIA GPU çš„ç»ˆæä¼˜åŒ–

### ğŸ’¡ ä½ä¼˜å…ˆçº§ï¼ˆé•¿æœŸè§„åˆ’ï¼‰

8. **æ¨¡å‹å‰ªæ** - éœ€è¦é‡æ–°è®­ç»ƒ
9. **çŸ¥è¯†è’¸é¦** - éœ€è¦è®­ç»ƒæµç¨‹
10. **æ¸è¿›å¼æ¨ç†** - å¤æ‚åº¦é«˜ï¼Œåº”ç”¨åœºæ™¯æœ‰é™

---

## å®æ–½å»ºè®®

### çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰
```bash
âœ… æ¢¯åº¦æ£€æŸ¥ç‚¹ - æ˜¾å­˜ä¼˜åŒ–
âœ… æ‰¹å¤„ç†ä¼˜åŒ– - æ€§èƒ½æå‡
âœ… æ¨ç†ç¼“å­˜ - é‡å¤åœºæ™¯ä¼˜åŒ–
```

### ä¸­æœŸï¼ˆ1-2æœˆï¼‰
```bash
ğŸ”„ åŠ¨æ€è¾“å…¥å°ºå¯¸ - æ™ºèƒ½åŒ–ä¼˜åŒ–
ğŸ”„ æ¨¡å‹é‡åŒ– - æ˜¾å­˜å¤§å¹…å‡å°‘
ğŸ”„ ONNX å¯¼å‡º - è·¨å¹³å°æ”¯æŒ
```

### é•¿æœŸï¼ˆ3-6æœˆï¼‰
```bash
â³ TensorRT é›†æˆ - æè‡´æ€§èƒ½
â³ æ¨¡å‹å‰ªæå’Œè’¸é¦ - æ¨¡å‹ä¼˜åŒ–
â³ å®Œæ•´çš„ä¼˜åŒ–å·¥å…·é“¾
```

---

## æ€§èƒ½å¯¹æ¯”è¡¨

| ä¼˜åŒ–æ–¹æ¡ˆ | æ˜¾å­˜å‡å°‘ | é€Ÿåº¦æå‡ | å®æ–½éš¾åº¦ | ä¼˜å…ˆçº§ |
|---------|---------|---------|---------|--------|
| å·²å®ç°ä¼˜åŒ– | 40-50% | 20-30% | - | - |
| æ¢¯åº¦æ£€æŸ¥ç‚¹ | 30-50% | -10-20% | â­â­ | ğŸ”¥ é«˜ |
| æ‰¹å¤„ç†ä¼˜åŒ– | 0% | 50-80% | â­ | ğŸ”¥ é«˜ |
| æ¨ç†ç¼“å­˜ | 0% | 90%+ | â­ | ğŸ”¥ é«˜ |
| åŠ¨æ€è¾“å…¥å°ºå¯¸ | 30-50% | 20-30% | â­â­ | ğŸ”¥ é«˜ |
| æ¨¡å‹é‡åŒ– | 75% | 2-3å€ | â­â­â­ | â­ ä¸­ |
| ONNX å¯¼å‡º | 20% | 20-30% | â­â­ | â­ ä¸­ |
| TensorRT | 30% | 3-5å€ | â­â­â­â­ | â­ ä¸­ |
| æ¨¡å‹å‰ªæ | 30-50% | 1.5-2å€ | â­â­â­â­â­ | ğŸ’¡ ä½ |
| çŸ¥è¯†è’¸é¦ | 50-70% | 2-3å€ | â­â­â­â­â­ | ğŸ’¡ ä½ |
| æ¸è¿›å¼æ¨ç† | 50% | 4-6å€ | â­â­â­ | ğŸ’¡ ä½ |

---

## é…ç½®æ–‡ä»¶ç¤ºä¾‹

```yaml
# config.yaml
optimization:
  # æ¢¯åº¦æ£€æŸ¥ç‚¹
  gradient_checkpointing: false
  checkpoint_segments: 3
  
  # åŠ¨æ€è¾“å…¥å°ºå¯¸
  dynamic_input_size: false
  min_input_size: 512
  max_input_size: 1536
  
  # æ‰¹å¤„ç†
  enable_batch_processing: false
  max_batch_size: 4
  
  # æ¨ç†ç¼“å­˜
  enable_cache: false
  cache_size: 100
  
  # æ¨¡å‹é‡åŒ–
  enable_quantization: false
  quantization_mode: "dynamic"  # dynamic, static
  
  # TensorRT
  enable_tensorrt: false
  tensorrt_fp16: true
```

---

## æ€»ç»“

è¿™äº›ä¼˜åŒ–æ–¹æ¡ˆå¯ä»¥æ˜¾è‘—æå‡ MLSharp çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤§é‡è¯·æ±‚æˆ–æœ‰é™æ˜¾å­˜çš„ç¯å¢ƒä¸‹ã€‚å»ºè®®æ ¹æ®å®é™…éœ€æ±‚å’Œèµ„æºæƒ…å†µï¼Œé€‰æ‹©åˆé€‚çš„ä¼˜åŒ–æ–¹æ¡ˆé€æ­¥å®æ–½ã€‚

**é¢„æœŸæ€»ä½“æå‡**:
- æ˜¾å­˜å ç”¨: å‡å°‘ 50-70%
- æ¨ç†é€Ÿåº¦: æå‡ 3-5 å€
- ååé‡: æå‡ 5-10 å€

**å…³é”®æˆåŠŸå› ç´ **:
1. æ ¹æ®ç¡¬ä»¶é…ç½®é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–æ–¹æ¡ˆ
2. å¹³è¡¡æ€§èƒ½å’Œç²¾åº¦
3. å……åˆ†æµ‹è¯•å’ŒéªŒè¯
4. ç›‘æ§æ€§èƒ½æŒ‡æ ‡
5. é€æ­¥å®æ–½å’Œä¼˜åŒ–